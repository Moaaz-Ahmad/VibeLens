# VibeLens â€” AI Mood-Based Music Discovery

> Point your camera at a scene. Capture its mood. Get a perfect Spotify playlist.

VibeLens uses on-device AI to analyze visual scenes and generate personalized music playlists that match the emotional atmosphere of your surroundings.

## âœ¨ Features

- **ğŸ¤– On-device AI** â€” Privacy-first mood detection using TensorFlow Lite
- **ğŸ“¸ Real-time camera** â€” Instant mood classification from your surroundings  
- **ğŸµ Spotify integration** â€” Automatic playlist generation based on detected mood
- **ğŸ¨ Mood visualization** â€” Beautiful gradients that reflect detected emotions
- **âš¡ Fast & lightweight** â€” <800ms inference, Material Design 3 UI

## ğŸ—ï¸ Architecture

```
Camera Frame â†’ TFLite Model (MobileNetV2) â†’ Mood Classification â†’ Spotify API â†’ Playlist
```

**Tech Stack:**

- **Frontend:** Flutter 3.16+ with Material Design 3
- **ML Model:** Pre-trained MobileNetV2 (adapted for 6 mood classes)
- **ML Runtime:** TensorFlow Lite (uint8 quantized)
- **APIs:** Spotify Web API
- **State:** Riverpod 2.4+
- **Storage:** flutter_secure_storage

## ğŸš€ Quick Start

### Prerequisites

- Flutter SDK 3.16+
- Dart 3.2+
- Android Studio / Xcode
- Python 3.9-3.13 (for model training/conversion)
- Spotify Developer Account

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/vibelens.git
cd vibelens

# Install Flutter dependencies
flutter pub get

# Create .env file with Spotify credentials
cp .env.example .env
# Edit .env and add your Spotify Client ID and Secret

# Run the app
flutter run
```

### Model Setup (Optional - Pre-trained model included)

The app comes with a pre-trained MobileNetV2 model. To retrain:

```bash
cd ml
pip install -r requirements.txt

# Use pre-trained MobileNetV2
python use_pretrained.py

# Test the model
python test_pretrained.py --image path/to/image.jpg

# Convert to TFLite (use Google Colab for Python 3.9 compatibility)
# Upload colab_tflite_conversion.ipynb to Colab
# Follow instructions in PRETRAINED_QUICKSTART.md
```

## ğŸ“± Usage

1. **Launch app** and grant camera permissions
2. **Point camera** at any scene (workspace, window view, cafÃ©, etc.)
3. **Tap "Capture Mood"** to analyze the scene
4. **View results** â€” See detected mood with confidence score
5. **Generate playlist** â€” Get Spotify recommendations (requires auth)

## ğŸ¨ Mood Categories

| Mood | Emoji | Description | Gradient |
|------|-------|-------------|----------|
| **Cozy** | ğŸ›‹ï¸ | Warm, comfortable, intimate | Orange-Red |
| **Energetic** | âš¡ | Dynamic, vibrant, high-energy | Yellow-Green |
| **Melancholic** | ğŸŒ§ï¸ | Reflective, somber, introspective | Gray-Blue |
| **Calm** | ğŸŒŠ | Peaceful, serene, tranquil | Light Blue |
| **Nostalgic** | ğŸ“¸ | Sentimental, vintage, reminiscent | Sepia-Brown |
| **Romantic** | ğŸ’• | Loving, intimate, tender | Pink-Red |

## ğŸ§ª Current Status

| Feature | Status |
|---------|--------|
| Pre-trained MobileNetV2 model | âœ… Complete |
| TFLite conversion | âœ… Complete |
| Flutter app with camera | âœ… Complete |
| Mood detection (uint8) | âœ… Complete |
| UI with mood gradients | âœ… Complete |
| Spotify OAuth setup | âœ… Complete |
| Widget tests (22 passing) | âœ… Complete |
| Production model training | ğŸ”„ In progress |
| Full Spotify integration | ğŸ”„ In progress |

**Latest Updates:**

- âœ… Fixed uint8 input/output data type handling
- âœ… Refactored code with centralized constants and theme
- âœ… Added comprehensive logging with Logger utility
- âœ… Created 22 passing unit tests
- âœ… App running successfully on Android emulator

## ğŸ› ï¸ Development

### Project Structure

```
vibelens/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ main.dart                 # App entry point
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ constants.dart        # App-wide constants
â”‚   â”‚   â”œâ”€â”€ theme.dart            # Material Design 3 theme
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ logger.dart       # Logging utility
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â”œâ”€â”€ splash_screen.dart
â”‚   â”‚   â”œâ”€â”€ camera_screen.dart
â”‚   â”‚   â”œâ”€â”€ results_screen.dart
â”‚   â”‚   â”œâ”€â”€ playlist_screen.dart
â”‚   â”‚   â””â”€â”€ settings_screen.dart
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ model_service.dart    # TFLite inference
â”‚   â”‚   â”œâ”€â”€ camera_service.dart   # Camera handling
â”‚   â”‚   â””â”€â”€ spotify_service.dart  # Spotify API
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ mood_result.dart      # Data models
â”‚   â””â”€â”€ widgets/                  # Reusable components
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ use_pretrained.py         # Download pre-trained model
â”‚   â”œâ”€â”€ test_pretrained.py        # Test model locally
â”‚   â”œâ”€â”€ colab_tflite_conversion.ipynb  # Convert to TFLite
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ checkpoints/
â”‚           â””â”€â”€ pretrained_mobilenet_mood.pth
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ mood_classifier.tflite  # Deployed model
â”œâ”€â”€ test/
â”‚   â””â”€â”€ widget_test.dart          # 22 passing tests
â”œâ”€â”€ android/                      # Android config
â”œâ”€â”€ ios/                          # iOS config
â””â”€â”€ .env                          # Spotify credentials
```

### Running Tests

```bash
# Run all tests (22 tests)
flutter test

# Run with coverage
flutter test --coverage

# Analyze code
flutter analyze
```

### Building Release

```bash
# Android APK
flutter build apk --release

# Android App Bundle
flutter build appbundle --release

# iOS (requires Mac)
flutter build ios --release
```

## ğŸ” Spotify API Setup

1. Go to [Spotify Developer Dashboard](https://developer.spotify.com/dashboard)
2. Create a new app
3. Add redirect URI: `vibelens://callback`
4. Copy Client ID and Client Secret
5. Create `.env` file in project root:

```env
SPOTIFY_CLIENT_ID=your_client_id_here
SPOTIFY_CLIENT_SECRET=your_client_secret_here
SPOTIFY_REDIRECT_URI=vibelens://callback
```

## ğŸ“š Documentation

- **[ARCHITECTURE.md](ARCHITECTURE.md)** â€” Technical architecture details
- **[PRETRAINED_QUICKSTART.md](PRETRAINED_QUICKSTART.md)** â€” Quick start with pre-trained model
- **[PRETRAINED_IMPLEMENTATION.md](PRETRAINED_IMPLEMENTATION.md)** â€” Implementation details
- **[REFACTORING_COMPLETE.md](REFACTORING_COMPLETE.md)** â€” Code refactoring summary
- **[APP_LAUNCH_STATUS.md](APP_LAUNCH_STATUS.md)** â€” App launch guide
- **[NEXT_STEPS.md](NEXT_STEPS.md)** â€” Development roadmap

## ğŸ› Troubleshooting

### Model Inference Error
If you see "invalid argument: input element is double while tensor data type is uint8":

- âœ… Fixed in current version
- Model expects uint8 (0-255), preprocessing converts images correctly

### Camera Permission Denied

- Grant camera permission in Android settings
- For emulator, ensure virtual camera is enabled

### Spotify Auth Failed

- Verify credentials in `.env` file
- Check redirect URI matches dashboard settings
- Ensure internet connection is active

## ğŸ“Š Performance Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Inference time | ~700ms | <200ms |
| Model size (TFLite) | ~3-5MB | <15MB |
| App size (APK debug) | ~45MB | <60MB |
| Test coverage | 22 tests | >50 tests |

## ğŸ—ºï¸ Roadmap

### Phase 1: MVP âœ…

- [x] Flutter app scaffold
- [x] Camera integration
- [x] Pre-trained MobileNetV2
- [x] TFLite inference
- [x] Basic UI with mood display
- [x] Unit tests

### Phase 2: Features ğŸ”„

- [x] Spotify OAuth setup
- [ ] Full playlist generation
- [ ] Playlist playback
- [ ] Settings screen
- [ ] Mood history

### Phase 3: Polish ğŸ“…

- [ ] Custom model training on dataset
- [ ] Performance optimization
- [ ] UI/UX refinements
- [ ] Integration tests
- [ ] Beta release

## ğŸ¤ Contributing

This is a portfolio/learning project. Feel free to fork and experiment!

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) file

---

**Built with Flutter ğŸ’™ | On-device AI ğŸ§  | Music discovery ğŸµ**
